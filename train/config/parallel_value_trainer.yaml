model_name: meta-llama/Meta-Llama-3.1-8B-Instruct
cache_dir: null

dataset_name: numina-v1-blocks
balance_dataset: false

use_flash_attn: false
seed: 42

test_freq: 100
save_freq: 200
num_test_batches: 20
wandb_project: prm_bc
wandb_entity: null
wandb_run_name: prm_bc_small
output_dir: /home/violet/checkpoints/
# huggingface save info
hf_organization: violetxi


gradient_accumulation_steps: 64
train_batch_size: 4
test_batch_size: 12
lr: 1e-5
epochs: 1
warmup_ratio: 0.03
low_cpu_mem_usage: true
loss: bce  #bce_weighted    #  ['kl', 'bce', 'huber']
discounted_rewards: false
evaluate_math500_orm: false
mixed_precision: bf16
debug: false
weight_decay: 0.0
